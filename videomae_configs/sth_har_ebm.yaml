# videomae_configs/sth_har_ebm.yaml

# ===================================================================
#                       通用配置
# ===================================================================
# --- 基本信息 (来自 kinetics_finetune_sth.yaml) ---
dataset: sthv2
data_path: ../sthv2
ckpt_path: ./checkpoints
exp_name: videomaev2_base_ebm_sthv2 # 实验名: 融合EBM和STHV2微调
model_type: videomae
seed: 42

# --- 数据处理 & 模型配置 (来自 kinetics_finetune_sth.yaml) ---
train_batch_size: 16
val_batch_size: 4
workers: 12
clip_len: 16
# --- 模型结构配置：使用VideoMAEv2-Base的官方配置 ---
model_cfg_path: ../mmaction2/configs/recognition/videomaev2/vit-base-p16_videomaev2-vit-g-dist-k710-pre_16x4x1_kinetics-400.py
# --- 预训练权重：使用在Kinetics-400上预训练的权重 ---
model_ckpt_path: "../pretrained_checkpoints/vit-base-p16_videomaev2-vit-g-dist-k710-pre_16x4x1_kinetics-400_20230510-3e7f93b2.pth"
# --- 关键修改：确保类别数和特征维度正确 ---
num_classes: 20 # 注意：请根据你的STHV2子集的实际类别数修改此值
embed_dim: 768  # VideoMAEv2-Base 模型的特征维度是 768

# ===================================================================
#             阶段 1: 特征两端提取法
# (参数参考 ucf_har_ebm.yaml 和 hmdb_har_ebm.yaml)
# ===================================================================
initial_labeled_ratio: 0.05
budget_labels: 2000 # STHV2数据集较大，预算相应增加
num_each_iter: 20

# --- 启用的特征策略 (用于生成best/worst对) ---
use_statistical_features: true
use_diversity_feature: true
use_representativeness_feature: true
use_prediction_margin_feature: true
use_labeled_distance_feature: true
use_neighborhood_density_feature: true
use_temporal_consistency_feature: true

# ===================================================================
#                       阶段 2: 奖励模型训练
# ===================================================================
reward_model_type: ebm # <-- 关键: 指定使用EBM

# ===================================================================
#                       阶段 3: RL智能体训练
# ===================================================================
al_algorithm: dqn
# --- 训练设置 (融合了finetune和AL的配置) ---
optimizer:
  type: 'SGD'
  lr: 0.004           # <-- 使用kinetics_finetune_sth.yaml中为sthv2优化的学习率
  weight_decay: 0.05

epoch_num: 100        # AL流程使用更多的epochs
patience: 20
al_train_epochs: 15

param_scheduler:
  - type: 'MultiStepLR'
    begin: 0
    end: 100
    by_epoch: True
    milestones: [40, 80] # 匹配新的epoch_num
    gamma: 0.1

# --- DQN 智能体训练参数 (参考 ucf_har_ebm.yaml) ---
lr_dqn: 0.0001
gamma_scheduler_dqn: 0.99
rl_pool: 10
rl_buffer: 100
dqn_bs: 20 # 与num_each_iter保持一致
dqn_gamma: 0.99